<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<meta name="description" content="Talk at ELSC, May 31st, 2018">
		<meta name="author" content="Ariel Rokem">

		<title> Challenges and opportunities for computational neuroscience </title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/arokem.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
	<div class="reveal">
	<div class="slides">

	<section>
		<img src="img/eScience.png" height="100px" alt="eScience logo" align="middle">

		<h2> The era of brain observatories </h2>
		<h3><div align=middle> Challenges and opportunities for computational neuroscience </div></h3>
		<h4>May 31st, 2018, Edmund and Lily Safra Center for Brain Sciences</h4>
		<br>
		<p><a href="http://arokem.org">Ariel Rokem</a>,
		<a href="http://escience.washington.edu">University of Washington eScience Institute</a> </p>
		<p>  <small>Follow along at: <t><a href=""></t></a></small></p>
		<img src="img/cc-by.png" height="30px" alt="License" align="middle">
	</section>


	<section data-background-image="./img/CompSci-X5.jpg" data-background-size="cover" style="background: rgba(255, 255, 255, 0.8);">
		<blockquote>
			<img src="img/eScience.png" width="800px">
			<small><em>"All across our campus, the process of discovery will increasingly rely on researchersâ€™ ability to extract knowledge from vast amounts of data... In order to remain at the forefront, UW must be a leader in advancing these techniques and technologies, and in making [them] accessible to researchers in the broadest imaginable range of fields"</em></small>
		</blockquote>
	</section>

	<section data-background-image="./img/radio-astronomy-survey.png" data-background-size="cover">
		<blockquote  style="background: rgba(255, 255, 255, 0);">
			<p style="color:#FFFFFF";>The era of brain observatories</p>
		</blockquote>
	</section>


	<section data-background-video="./img/allen_institute_spinning_cells.mp4" data-background-size="cover">
		<blockquote  style="background: rgba(255, 255, 255, 0);">
			<p style="color:#FFFFFF";>Allen Institute for Brain Science</p>
		</blockquote>
	</section>

	<section data-background-image="./img/hcplogo1.jpg" data-background-size="1000px">
	</section>

	<section data-background-image="./img/UKBiobank_Brain_Imaging.001.jpeg" data-background-size="1000px" data-background-color="black">
	</section>


	<section>
		<h2>Opportunities</h2>
		<p class="fragment">New data sets enable new analysis methods</p>
		<p class="fragment">Data-driven discovery</p>
	</section>

	<section>
		<h2>Machine learning</h2>
		<p class="fragment">Learning from data</p>
		<p class="fragment">Features of the data are extracted/engineered</p>
		<p class="fragment">Training data is used to infer model parameters</p>
		<p class="fragment">Test data is used to evaluate accuracy</p>
	</section>

	<section>
		<h2>Challenges</h2>
		<p class="fragment">Methods that work in standard use may fail in large datasets</p>
		<p class="fragment">Interpretation challenges</p>
		<p class="fragment">Large-scale analysis requires large-scale computation</p>
		<p class="fragment">Existing sociotechnical structures are strained <br> (training, publication, collaboration)</p>
	</section>


		<section>
			<h2>Opportunity: learning from large-scale datasets</h2>
			<div style="position: absolute; left:170px; top 10px;">
				<img src="img/sa.jpeg" height="200">
				<br>
				Sa Xiao
			</div>
			<div style="position: absolute; left:580px; top 10px;">
				<img src="img/aaron.jpeg" height="200">
				<br>
				Aaron Lee
			</div>
			<div style="position: absolute; left:375px; top 10px;">
				<img src="img/parmita.jpeg" height="200">
				<br>
				Parmita Mehta
			</div>
		</section>

		<section>
			<h2>Artificial neural networks</h2>
			<p class="fragment">A family of machine learning algorithms</p>
			<p class="fragment">Biologically inspired</p>
			<div class="cite">
				<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
			</div>
		</section>

		<section>

			<h2>Artificial neural networks</h2>
			<img src="img/minsky_papert.png">
			<div class="cite">Minsky and Papert (1969)</div>
		</section>

		<section>
			<h2> Artificial neural networks</h2>
			<p>A family of machine learning algorithms</p>
			<p>Biologically inspired</p>
			<p class="fragment">Implement a cascade of linear/non-linear operations</p>
			<div class="cite">
				<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
			</div>
		</section>

		<section>
			<img src="img/simple-network.png">
			<div class="cite">
				<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
			</div>
		</section>

		<section>
			<h2> Artificial neural networks</h2>
			<p>A family of machine learning algorithms</p>
			<p>Biologically inspired</p>
			<p>Implement a cascade of linear/non-linear operations</p>
			<p class="fragment">Learn by back-propagating the errors through the network</p>
			<div class="cite">
				<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
			</div>
		</section>

		<section>
			<img src="img/simple-backprop.png">
			<div class="cite">
				<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
			</div>
		</section>

		<section>
			<h2> Convolutional networks</h2>
			<p class="fragment">A way to reduce the number of parameters</p>
			<p class="fragment">Capitalizes on spatial correlations in images</p>
			<p class="fragment">Inspired by the mammalian visual system</p>

			<div class="cite">
				<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
			</div>

		</section>

		<section>
			<img src="img/bosking.jpg" height=500>

			<div class="cite">
				<a href="http://www.jneurosci.org/content/17/6/2112.long">Bosking et al. 1997</a>
			</div>

		</section>

		<section>
			<img src="img/convolution_animation.gif">

			<div class="cite">
				<a href="https://arxiv.org/abs/1603.07285">Dumoulin and Visin (2016)</a>
			</div>
		</section>

		<section>
			<div style="position: absolute; left:10px; top:10px;">
				<img src="img/wall.png" height=250px;>
			</div>
			<div class="fragment" style="position: absolute; left:370px; top 10px;">
				<img src="img/horizontal_wall.png" height=220px;>
			</div>
			<div class="fragment" style="position: absolute; left:650px;">
				<img src="img/vertical_wall.png" height=220px;>
			</div>
		</section>

		<section>
			<img src="img/neural-network.png">
			<div class=cite>
				<a href="https://research.google.com/pubs/pub38115.html">Le et al. (2012)</a>
			</div>
		</section>

		<section>
			<img src="img/imagenet-fig4l.png">
			<div class=cite>
				<a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizhevsky et al. 2012</a>
			</div>
		</section>

		<section>
			<div align=center><h4>Optical Coherence Tomography (OCT)</h4>
				High-fidelity <em> in vivo </em> measurements of retinal structure at micron resolution
				<div class="fragment" align="middle">
					<image src="img/OCT.png" width="400px">
				</div>
				<div class="fragment" align="middle">
					<image src="img/OCT-irf.png" width="400px">
				</div>
		</section>

		<section>
			<h4>The UW OCT/EMR data-base</h4>
			<div class="fragment" style="position: absolute; left: 10px; top: 55px;" >
				<p class="fragment">
					10 years (2006-2016)
				<p class="fragment">
					9,285 patients
				<p class="fragment">
					43,328 OCT volumes
				<p class="fragment">
					2.64 million OCT images
				<p class="fragment">
					2.5 TB of data
			</div>
			<div style="position: absolute; left: 400px; top: 55px;" >
				<p class="fragment">Linked to EPIC electronic medical records
				<p class="fragment"> For each OCT we know:
					<small>
				<p class="fragment"> Visual acuity
				<p class="fragment"> OCT interpretation
				<p class="fragment"> Diagnosis
				<p class="fragment"> Treatment determinations
				<p class="fragment"> In some cases - longitudinal measurements
					</small>
			</div>
		</section>

		<section>
			<h4>Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration </h4>
			<img src="img/amd-vgg16-results.png" height=400px>
			<div class=cite>
				<a href="">Lee et al. (2016)</a>
			</div>
		</section>


		<section>
			<h4><div align="center">Is there a ball in the picture?</div></h4>
			<image src="img/dog-with-ball.png" height="400px">
				<div class=cite>
					><a href="https://arxiv.org/pdf/1311.2901.pdf">Zeiler and Fergus (2013)</a>
				</div>
		</section>

		<section>
			<h4><div align="center">How about now?</div></h4>
			<image src="img/dog-with-ball-occluder-corner.png" height="400px">
				<div class=cite>
					><a href="https://arxiv.org/pdf/1311.2901.pdf">Zeiler and Fergus (2013)</a>
				</div>
		</section>

		<section>
			<h4><div align="center">And now?</div></h4>
			<image src="img/dog-with-ball-occluder-center.png" height="400px">

				<div class=cite>
					<a href="https://arxiv.org/pdf/1311.2901.pdf">Zeiler and Fergus (2013)</a>
				</div>
		</section>

		<section>
			<h4><div align="center">Deep learning network identifies clinical features</div></h4>
			<image src="./img/amd-vgg16-occlusion.png" height="500px">
				<div class=cite>
					<a href="">Lee et al. (2016)</a>
				</div>
		</section>


		<section>
			<h4>Solving multi-class multi-label problems</h4>
			<p class="fragment">Binary classification doesn't model clinical decision making </p>
			<p class="fragment">Patients can have any of a several diseases</p>
			<p class="fragment">Patients can have more than one disease</p>
			<div class=cite>
				<a href="">Mehta et al. (2016)</a>
			</div>

		</section>

		<section>
			<h4>Augmenting the neural network with additional patient information</h4>
			<img src="img/multi_class_multi_label.png">
		</section>


		<section>
			<h2>Fully convolutional networks</h2>
			Take an image as input and produce an image as output
		</section>

		<section>
			<img src="img/unet-architecture.png" height=500px>
			<div class=cite>
				<a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">Ronneberger et al. 2015</a>
			</div>
		</section>

		<section>
			<h4><div align="center">Intraretinal fluid segmentation</div></h4>
			<image src="./img/unet-segmentation-1.png" height="500px">
				<div style="position: absolute; left: 700px; top: 620px" >
					<small><a href="">Lee et al. (2016)</a>
					</small>
				</div>
		</section>

		<section>
			<h4><div align="center">Intraretinal fluid segmentation</div></h4>
			<image src="./img/unet-segmentation-2.png" height="500px">
				<div style="position: absolute; left: 700px; top: 620px" >
					<small><a href="">Lee et al. (2016)</a>
					</small>
				</div>
		</section>

		<section>
			<h4><div align="center">Intraretinal fluid segmentation</div></h4>
			<image src="./img/unet-vs-humans.png" height="500px">
				<div style="position:absolute; left:580px;top:70px">
					<image src="./img/white-square.png" height="500px">
				</div>
				<div style="position: absolute; left: 700px; top: 620px" >
					<small><a href="">Lee et al. (2016)</a>
					</small>
				</div>
		</section>

		<section>
			<h4><div align="center">Intraretinal fluid segmentation</div></h4>
			<image src="./img/unet-vs-humans.png" height="500px">
				<div style="position: absolute; left: 700px; top: 620px" >
					<small><a href="">Lee et al. (2016)</a>
					</small>
				</div>
		</section>


		<section>
			<h4>U-net based image synthesis</h4>
			<img src="img/UNET.png">
		</section>

		<section>
			<h4>OCT => OCTA </h4>
			<img src="img/oct2octa.png" height=500px>
			<div class=cite>
				<a href="https://www.biorxiv.org/content/early/2018/02/25/271346">Lee et al. (2018)</a>
			</div>
		</section>
		<section>
			<h4>OCT => OCTA </h4>
			<img src="img/oct2octa_cues.png">
			<div class=cite>
				<a href="https://www.biorxiv.org/content/early/2018/02/25/271346">Lee et al. (2018)</a>
			</div>
		</section>

		<section>
			<h4>MRI => MRI </h4>
			<video width="800" autoplay loop>
				<source src="img/t2t1.mov">
			</video>
		</section>

		<section>
			<h4>MRI => MRI </h4>
			<img src="./img/t2t1_rsquared.png">
		</section>

		<section>
			<h4>MRI => MRI </h4>
			<img src="./img/t2t1_synth_rsquared.png">
		</section>

		<section>
			<h3>What is this good for?</h3>
			<h3 class="fragment">Application: cross-modal image registration</h3>
			<h3 class="fragment">An example with diffusion MRI</h3>
		</section>

		<section>
			<img src="./img/dti_reg.png" height=400>
		</section>

		<section>
			<img src='img/compare_registrations.png'>
		</section>

		<section>
			<h2>Summary and conclusions</h2>
			<p class="fragment">Fully convolutional neural networks are used for cross-modal image synthesis</p>
			<p class="fragment">There are already applications (e.g., cross-modal registration)</p>
			<p class="fragment">But more questions that answers: </p>
			<p class="fragment">What is it learning?</p>
			<p class="fragment">Can it tell us anything new about the physics of contrast mechanisms?</p>

		</section>

	<section>
		<h2>Opportunity: learning structure</h2>
		<div style="position: absolute; left:40px; top 10px;">
		<img src="img/adam.jpeg" height="300">
			<br>
			Adam Richie-Halford
		</div >
		<div style="position: absolute; left:350px; top 10px;">
		<img src="img/noah.jpg", height="300">
			<br>
			Noah Simon
		</div>
		<div style="position: absolute; left:600px; top 10px;">
		<img src="img/jason.jpg" height="300">
		<br>
		Jason Yeatman
		</div>

	</section>

	<section>
		<h2>Automated Fiber Quantification (AFQ)</h2>
		<img src="img/afq1.png" height="420">

		<div class="cite">
			<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0049790">Yeatman et al. (2012)</a>
		</div>
	</section>


	<section>
		<h2>Automated Fiber Quantification (AFQ)</h2>
		<img src="img/afq2.png" height="420">

		<div class="cite">
			<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0049790">Yeatman et al. (2012)</a>
		</div>
	</section>

	<!--
	<section>
		<h2>Automated Fiber Quantification (AFQ)</h2>
		<img src="img/afq3.png" height="420">

		<div class="cite">
			<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0049790">Yeatman et al. (2012)</a>
		</div>
	</section>

	<section>
		<h2>Automated Fiber Quantification (AFQ)</h2>
		<img src="img/afq4.png" height="420">

		<div class="cite">
			<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0049790">Yeatman et al. (2012)</a>
		</div>
	</section>

	<section>
		<h2>Challenges</h2>
		<p class="fragment">Mass univariate analysis</p>
		<p class="fragment">ROI-based analysis</p>
	</section>
	-->

	<section>
		<h2>Amyotrophic Lateral Sclerosis (ALS)</h2>
		<p class="fragment">Disease of upper and lower motor neurons</p>
		<p class="fragment">=>Focus on corticospinal tract</p>
		<img class="fragment" src="img/sarica_results.png">
		<p class="fragment">Classify patients based on the tissue properties in this part of the brain</p>
		<p class="fragment">=> 80% accuracy</p>
		<div class="cite">
			<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23412">Sarica et al. (2017)</a>
		</div>

	</section>


	<section>
		<h2>Data-driven approach</h2>
		<img src="img/sgl_design.png" height="500px">
	</section>

	<section>
		<h2>Logistic regression</h2>
		<img src="img/logistic_regression.png" width="600px">
		<p class="fragment">But in our case p (number of variables) >> n (number of subjects) </p>
	</section>

	<section>
		<h2>The Lasso</h2>
		<img src="img/lasso_penalty.png" width="400px">
		<p class="fragment">But the standard lasso ignores the known structure in the data</p>
	<div class="cite">
		<a href="http://statweb.stanford.edu/~tibs/lasso/lasso.pdf">Tibshirani (1996)</a>
	</div>
	</section>

	<section>
		<h2>The Group Lasso</h2>
	<img src="img/group_lasso_penalty.png" width="600px">
	<p class="fragment">But the group lasso does not enforce overall sparsity</p>
	<div class="cite">
		<a href="http://www.columbia.edu/~my2550/papers/glasso.final.pdf">Yuan and Lin</a>
	</div>
	</section>
	<section>
		<h2>Sparse Group Lasso</h2>
		<img src="img/sparse_group_lasso_penalty.png" width="600px">
		<div class="cite">
			<a href="https://www.tandfonline.com/doi/abs/10.1080/10618600.2012.681250">Simon et al. (2013)</a>
		</div>
	</section>

	<section>
		<h2>Fitting meta-parameters</h2>
		<p class="fragment">Nested cross-validation</p>

		XXX

	</section>

	<section>
		<img src="img/sgl_result.png">
		<p class="fragment">=> Classification accuracy of ~84%, AUC of 0.9 </p>
	</section>

	<section>
		<h2>Challenge: Methods that work in standard datasets may fail in Big Data</h2>
		<h3 class="fragment">Research protocols that require expert examination</h3>
		<h3 class="fragment">Time consuming, tedious</h3>
		<h3 class="fragment">=> Do not scale well!</h3>
	</section>


	<section>
		<h2>Scaling expertise with citizen science</h2>
		<div style="position: absolute; left:200px; top 10px;">
		<img src="img/anisha.jpg" height="300">
			<br>
			Anisha Keshavan
		</div>

		<div style="position: absolute; left:420px; top 10px;">
			<img src="img/jason.jpg" height="300">
			<br>
			Jason Yeatman
		</div>
	</section>

	<section>
		<h2>The solution</h2>
		<h3 class="fragment">Train machine learning algorithms</h3>
		<h3 class="fragment">But: for many tasks, not enough training data</h3>
		<h3 class="fragment">=> Amplify labeled data-sets with citizen science</h3>

	</section>

	<section>
		<h2>Example</h2>
		<h3 >Quality control of T1-weighted images</h3>
		<img src="img/t1_qc.png" height="300">
		<div class="cite">
			<a href="https://www.nature.com/articles/sdata2017181">Human Brain Network <br>(Alexander et al. 2017)</a>
		</div>
	</section>

	<section>
		<h4><a href="https://braindr.us">https://braindr.us</a></h4>

		<img src="img/braindr.gif">

		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>

	</section>

	<section>
		<h2>Braindr</h2>
		<div style="position: absolute; left:200px; top 10px;">
		<blockquote class="twitter-tweet" data-lang="en">
			<p lang="en" dir="ltr">Are you at work but feel like playing Tinder? Why not play braindr (<a href="https://t.co/yXw191Q7Hy">https://t.co/yXw191Q7Hy</a>) instead, and help neuroscientists rate the quality of brain images? Swipe left to fail bad quality images! Built with <a href="https://twitter.com/vuejs?ref_src=twsrc%5Etfw">@vuejs</a> and <a href="https://twitter.com/Firebase?ref_src=twsrc%5Etfw">@Firebase</a> <a href="https://twitter.com/hashtag/citizenscience?src=hash&amp;ref_src=twsrc%5Etfw">#citizenscience</a> <a href="https://t.co/tpI9Y3UKOb">pic.twitter.com/tpI9Y3UKOb</a></p>&mdash; anisha (@akeshavan_)
			<a href="https://twitter.com/akeshavan_/status/961385285182353408?ref_src=twsrc%5Etfw">February 7, 2018</a></blockquote>
		<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
		</div>
		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>
	</section>

	<section>
		<h2>Multiple ratings per image</h2>
		<img src="img/braindr_ratings_per_img.png" height="500">
		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>

	</section>

	<section>
		<h2>But often, no agreement</h2>
		<img src="img/braindr_average_rating.png" height="500">
		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>
	</section>

	<section>
		<h2>Aggregating across raters</h2>
		<img src="img/braindr_rater_importance.png" height="500">
		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>
	</section>

	<section>
		<h2>Aggregating across raters</h2>
		<img src="img/braindr_xgboost_ratings.png" height="500">
		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>
	</section>


	<section>
		<h2>Aggregating across raters</h2>
		<img src="img/braindr_xgboost_results.png" height="500">
		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>
	</section>


	<section>
		<h2>Scaling expertise using citizen scientist ratings</h2>
		<img src="img/braindr_learning_curves.png" height="500">
		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>
	</section>


	<section>
		<h2>Scaling expertise using citizen scientist ratings</h2>
		<img src="img/braindr_final_rocs.png" height="500">
		<div class="cite">
			<a href="">Keshavan, Yeatman & Rokem (in prep)</a>
		</div>
	</section>



		<section>
	<h2>Sociotechnical challenges</h2>
	Incentives for data sharing
	Collaboration in open source software
	Training
	</section>



	<section>

			<div style="position:absolute; left: 200px; top:-120px;">
			<h2>Contact information</h2>
			</div>
			<div style="position:absolute; left: 220px; top:-50px;">
			<img src="img/globe-xxl.png" width="100px;" >
			<div style="position:absolute; left: 120px; top:40px;">http://arokem.org
			</div>
			</div>
			<div style="position:absolute; left: 220px; top:70px;">
			<img src="img/email-11-xxl.png" width="100px;" >
			<div style="position:absolute; left: 120px; top:40px;">arokem@gmail.com
			</div>
			</div>
			<div style="position:absolute; left: 220px; top:190px;">
			<img src="img/twitter-xxl.png" width="100px;" >
			<div style="position:absolute; left: 120px; top:40px;">@arokem
			</div>
			</div>
			<div style="position:absolute; left: 220px; top:310px;">
			<img src="img/github-6-xxl.png" width="100px;" >
			<div style="position:absolute; left: 120px; top:40px;">github.com/arokem
			</div>
			</div>

	</section>

	</div>
	</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				history: true,
				controls: false,
				progress: true,
				center: true,

				transition: 'fade', // none/fade/slide/convex/concave/zoom

				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
